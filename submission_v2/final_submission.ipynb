{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Submission Generator\n",
        "\n",
        "This notebook loads the trained model, validates the test ultimate dataset columns against train (excluding `TARGET`), and writes the final submission CSV in the required format under `senior_ds_test/data/final_submission/`.\n",
        "\n",
        "- Output name: `final_submission_firstname_lastname.csv` (edit the name cell)\n",
        "- Model: `final_solution/artifacts/json/model_lgbm.pkl`\n",
        "- Train schema: `final_solution/artifacts/csv/ultimate_dataset.csv`\n",
        "- Test data: `final_solution/artifacts/csv/ultimate_dataset_test.csv`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paths set.\n"
          ]
        }
      ],
      "source": [
        "# Paths and parameters\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "PROJECT_ROOT = Path('/home/miso/Documents/WINDOWS/monsoon')\n",
        "FINAL_SOLUTION = PROJECT_ROOT / 'final_solution'\n",
        "ART_JSON = FINAL_SOLUTION / 'artifacts' / 'json'\n",
        "ART_CSV = FINAL_SOLUTION / 'artifacts' / 'csv'\n",
        "\n",
        "SUBMIT_DIR = FINAL_SOLUTION / 'submission_v2' \n",
        "SUBMIT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Edit your name here\n",
        "FIRST_NAME = 'Mitul'\n",
        "LAST_NAME = 'Solanki'\n",
        "\n",
        "MODEL_PATH = ART_JSON / 'model_lgbm.pkl'\n",
        "SCHEMA_SAMPLE = ART_CSV / 'ultimate_dataset.csv'  # train schema\n",
        "ULTI_TEST = ART_CSV / 'ultimate_dataset_test.csv'  # test features\n",
        "\n",
        "print('Paths set.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model. Feature count: 52\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/miso/miniconda3/envs/ms/lib/python3.10/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.3.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load model and schema\n",
        "model = joblib.load(MODEL_PATH)\n",
        "schema_df = pd.read_csv(SCHEMA_SAMPLE, nrows=100)\n",
        "feature_cols = [c for c in schema_df.columns if c not in ['uid','NAME_CONTRACT_TYPE','TARGET']]\n",
        "print('Loaded model. Feature count:', len(feature_cols))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test shape: (46127, 52)\n"
          ]
        }
      ],
      "source": [
        "# Load test and validate columns (excluding TARGET)\n",
        "if not ULTI_TEST.exists():\n",
        "    raise FileNotFoundError(f'Missing {ULTI_TEST}. Build it with submission_v2 scripts.')\n",
        "\n",
        "test_df = pd.read_csv(ULTI_TEST)\n",
        "expected_train = set(schema_df.columns) - {'TARGET'}\n",
        "actual_test = set(test_df.columns)\n",
        "missing_in_test = expected_train - actual_test\n",
        "extra_in_test = actual_test - expected_train\n",
        "if missing_in_test:\n",
        "    raise ValueError(f\"Columns missing in test (excluding TARGET): {sorted(list(missing_in_test))[:20]}\")\n",
        "if extra_in_test:\n",
        "    print(f\"Note: Extra columns in test ignored by model: {sorted(list(extra_in_test))[:10]}\")\n",
        "\n",
        "X_test = test_df[[c for c in feature_cols if c in test_df.columns]].fillna(0)\n",
        "uid_col = 'uid' if 'uid' in test_df.columns else None\n",
        "print('Test shape:', X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote submission to: /home/miso/Documents/WINDOWS/monsoon/final_solution/submission_v2/final_submission_Mitul_Solanki.csv\n"
          ]
        }
      ],
      "source": [
        "# Predict and write submission\n",
        "import numpy as np\n",
        "\n",
        "proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X_test)\n",
        "\n",
        "# Build submission frame matching sample\n",
        "SAMPLE_PATH = PROJECT_ROOT / 'senior_ds_test' / 'data' / 'final_submission' / 'sample_submission.csv'\n",
        "sample = pd.read_csv(SAMPLE_PATH)\n",
        "sub = sample.copy()\n",
        "\n",
        "# Identify id and probability columns\n",
        "id_col = next((c for c in ['uid','id','customer_id','case_id'] if c in sub.columns), None)\n",
        "if id_col is None and uid_col is not None:\n",
        "    sub.insert(0, 'uid', test_df['uid'])\n",
        "    id_col = 'uid'\n",
        "\n",
        "prob_col = next((c for c in ['TARGET','probability','target','score'] if c in sub.columns), None)\n",
        "if prob_col is None:\n",
        "    if len(sub.columns) >= 2:\n",
        "        prob_col = sub.columns[1]\n",
        "    else:\n",
        "        sub['TARGET'] = 0.0\n",
        "        prob_col = 'TARGET'\n",
        "\n",
        "# Assign values\n",
        "if id_col and uid_col:\n",
        "    sub[id_col] = test_df[uid_col].values\n",
        "sub[prob_col] = proba\n",
        "\n",
        "# Write\n",
        "out_path = SUBMIT_DIR / f\"final_submission_{FIRST_NAME}_{LAST_NAME}.csv\"\n",
        "sub.to_csv(out_path, index=False)\n",
        "print('Wrote submission to:', out_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes on predictions and submission format\n",
        "\n",
        "- The model outputs probabilities of class 1 (default). We do not submit hard labels (0/1).\n",
        "- The second column in the submission CSV mirrors the header of `sample_submission.csv` (e.g., `TARGET` or `probability`).\n",
        "- The evaluator computes ROC-AUC from these probabilities on the hidden test labels.\n",
        "- If you need hard labels, apply a threshold to the probabilities separately (not part of this submission).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ms",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
